'# Basis function regression

'Some general linear algebra routines. These should probably live in the prelude.

vdot :: n=>Real -> n=>Real -> Real
vdot x y = sum for i. x.i * y.i

mmp :: l=>m=>Real -> m=>n=>Real -> l=>n=>Real
mmp m1 m2 = for i k. sum for j. m1.i.j * m2.j.k

mvp :: n=>m=>Real -> m=>Real -> n=>Real
mvp m v = for i. vdot m.i v

transpose :: n=>m=>Real -> m=>n=>Real
transpose x = for i j. x.j.i

inner :: n=>Real -> n=>m=>Real -> m=>Real -> Real
inner x m y = sum for (i,j). x.i * m.i.j * y.j

-- Conjugate gradients solver
solve :: A M. M=>M=>Real -> M=>Real -> M=>Real
solve mat b =
  x0 = for i::M. 0.0 * (real (asint i))  -- Work around imp lowering bug!
  ax = mvp mat x0
  r0.i = b.i - ax.i
  (xOut, _, _) = fold (x0, r0, r0) ..
     for s::M. lam (x, r, p).
       ap = mvp mat p
       alpha = vdot r r / vdot p ap
       x'.i = x.i + alpha * p.i
       r'.i = r.i - alpha * ap.i
       beta = vdot r' r' / (vdot r r + 0.000001)
       p'.i = r'.i + beta * p.i
       (x', r', p')
  xOut

'Make some synthetic data

type Nx = 100
noise = 0.1
(k1, k2) = splitKey 0

trueFun :: Real -> Real
trueFun x = x + sin (5.0 * x)

xs :: Nx=>Real
xs.i = rand (ixkey k1 i)

ys :: Nx=>Real
ys.i = trueFun xs.i + noise * randn (ixkey k2 i)

:plot zip xs ys
> <graphical output>

'Implement basis function regression

regress :: (Real -> d=>Real) -> n=>Real -> n=>Real -> d=>Real
regress featurize xRaw y =
  x = map featurize xRaw
  xT = transpose x
  solve (mmp xT x) (mvp xT y)

'Fit a third-order polynomial

poly :: A d. Real -> d=>Real
poly x = for n. pow x (real (asint n))

params :: 4=>Real
params = regress poly xs ys

predict :: Real -> Real
predict x = vdot params (poly x)

:plot xsTest = linspace@100 0.0 1.0
      zip xsTest (map predict xsTest)
> <graphical output>

'RMS error

rmsErr :: n=>Real -> n=>Real -> Real
rmsErr truth pred = sqrt $ mean for i. sq (pred.i - truth.i)

:p rmsErr ys (map predict xs)
> 0.11008144336019322
