'# Basis function regression

-- Conjugate gradients solver
solve : A M. M=>M=>Real -> M=>Real -> M=>Real
solve mat b =
  x0 = for i:M. 0.0
  ax = mvp mat x0
  r0.i = b.i - ax.i
  (xOut, _, _) = fold (x0, r0, r0) $
     \s:M (x, r, p).
       ap = mvp mat p
       alpha = vdot r r / vdot p ap
       x'.i = x.i + alpha * p.i
       r'.i = r.i - alpha * ap.i
       beta = vdot r' r' / (vdot r r + 0.000001)
       p'.i = r'.i + beta * p.i
       (x', r', p')
  xOut

'Make some synthetic data

type Nx = 100
noise = 0.1
(k1, k2) = splitKey (newKey 0)

trueFun : Real -> Real
trueFun x = x + sin (5.0 * x)

xs : Nx=>Real
xs.i = rand (ixkey k1 i)

ys : Nx=>Real
ys.i = trueFun xs.i + noise * randn (ixkey k2 i)

:plot zip xs ys
> <graphical output>

'Implement basis function regression

regress : (Real -> d=>Real) -> n=>Real -> n=>Real -> d=>Real
regress featurize xRaw y =
  x = map featurize xRaw
  xT = transpose x
  solve (mmp xT x) (mvp xT y)

'Fit a third-order polynomial

poly : A d. Real -> d=>Real
poly x = for n. pow x (real (asint n))

params : 4=>Real
params = regress poly xs ys

predict : Real -> Real
predict x = vdot params (poly x)

:plot
   xsTest = linspace@100 0.0 1.0
   zip xsTest (map predict xsTest)
> <graphical output>

'RMS error

rmsErr : n=>Real -> n=>Real -> Real
rmsErr truth pred = sqrt $ mean for i. sq (pred.i - truth.i)

:p rmsErr ys (map predict xs)
> 9.46494e-2
